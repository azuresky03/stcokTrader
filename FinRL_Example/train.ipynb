{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Packages ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "from stable_baselines3 import A2C, PPO, DDPG, TD3, SAC\n",
    "from stable_baselines3.common.logger import configure\n",
    "\n",
    "from finrl.meta.preprocessor.preprocessors import data_split\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent, DRLEnsembleAgent\n",
    "from finrl.plot import backtest_stats\n",
    "\n",
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    ")\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_START_DATE = '2014-06-01'\n",
    "TRAIN_END_DATE = '2021-01-01'\n",
    "TEST_START_DATE = '2021-01-02'\n",
    "TEST_END_DATE = '2023-04-01'\n",
    "TIME_INTERVAL = '1D'\n",
    "\n",
    "INDICATORS = [\n",
    "    \"macd\",\n",
    "    \"adx\",\n",
    "    \"rsi_30\",\n",
    "    \"boll_ub\",\n",
    "    \"boll_lb\",\n",
    "    \"close_30_sma\",\n",
    "    \"close_60_sma\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load stocks data from datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"datasets/processed_data.csv\")\n",
    "\n",
    "train = data_split(data, TRAIN_START_DATE, TRAIN_END_DATE)\n",
    "test = data_split(data, TEST_START_DATE, TEST_END_DATE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate all the parameters needed in the training process\n",
    "\n",
    "*   **stock_dimension**: the number of unique stocks\n",
    "*   **state_space**: the dimension of state space\n",
    "*   **action_space**: the dimension of action space\n",
    "*   **buy_cost_list**: a list of transaction cost percentages for buying stocks\n",
    "*   **sell_cost_list**: a list of transaction cost percentages for selling stocks\n",
    "*   **num_stock_shares**: the number of shares to buy/sell every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\"a2c\": A2C, \"ddpg\": DDPG, \"td3\": TD3, \"sac\": SAC, \"ppo\": PPO}\n",
    "# Parameter spaces for each model\n",
    "a2c_space = [\n",
    "    Integer(10, 200, name=\"n_steps\"),\n",
    "    Real(0.001, 0.1, \"log-uniform\", name=\"ent_coef\"),\n",
    "    Real(1e-5, 1e-2, \"log-uniform\", name=\"learning_rate\"),\n",
    "    Integer(32, 256, name=\"batch_size\"),\n",
    "]\n",
    "ddpg_space = [\n",
    "    Integer(10000, 1000000, name=\"buffer_size\"),\n",
    "    Real(1e-5, 1e-2, \"log-uniform\", name=\"learning_rate\"),\n",
    "    Integer(32, 256, name=\"batch_size\"),\n",
    "    Real(0.001, 0.1, \"log-uniform\", name=\"tau\"),\n",
    "]\n",
    "td3_space = [\n",
    "    Integer(10000, 1000000, name=\"buffer_size\"),\n",
    "    Real(1e-5, 1e-2, \"log-uniform\", name=\"learning_rate\"),\n",
    "    Integer(32, 256, name=\"batch_size\"),\n",
    "    Real(0.001, 0.1, \"log-uniform\", name=\"tau\"),\n",
    "    Real(0.01, 0.5, \"log-uniform\", name=\"policy_noise\"),\n",
    "    Real(0.01, 0.5, \"log-uniform\", name=\"noise_clip\"),\n",
    "    Integer(1, 10, name=\"policy_freq\"),\n",
    "]\n",
    "sac_space = [\n",
    "    Integer(10000, 1000000, name=\"buffer_size\"),\n",
    "    Real(1e-5, 1e-2, \"log-uniform\", name=\"learning_rate\"),\n",
    "    Integer(32, 256, name=\"batch_size\"),\n",
    "    Real(0.001, 0.1, \"log-uniform\", name=\"tau\"),\n",
    "    Real(0.001, 0.1, \"log-uniform\", name=\"ent_coef\"),\n",
    "]\n",
    "ppo_space = [\n",
    "    Integer(10, 200, name=\"n_steps\"),\n",
    "    Real(0.001, 0.1, \"log-uniform\", name=\"ent_coef\"),\n",
    "    Real(1e-5, 1e-2, \"log-uniform\", name=\"learning_rate\"),\n",
    "    Integer(32, 256, name=\"batch_size\"),\n",
    "]\n",
    "\n",
    "param_spaces = {\n",
    "    \"a2c\": a2c_space,\n",
    "    \"ppo\": ppo_space,\n",
    "    \"sac\": sac_space,\n",
    "    \"td3\": td3_space,\n",
    "    \"ddpg\": ddpg_space\n",
    "}\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 100000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "stock_env = StockTradingEnv(df=train, **env_kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model_name, env, model_kwargs):\n",
    "    # model training\n",
    "    agent = DRLAgent(env)\n",
    "    model = agent.get_model(model_name, model_kwargs = model_kwargs)\n",
    "    # set up logger\n",
    "    tmp_path = RESULTS_DIR + f\"{model_name}\"\n",
    "    new_logger_ppo = configure(tmp_path, [\"tensorboard\", \"stdout\"])\n",
    "    model.set_logger(new_logger_ppo)\n",
    "\n",
    "    trained_model = agent.train_model(model=model,\n",
    "                                        tb_log_name=model_name,\n",
    "                                        total_timesteps=50000)\n",
    "    return trained_model\n",
    "\n",
    "def model_eval(model_name, env, trained_model):\n",
    "    df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "        model=trained_model, environment = env)\n",
    "    stats  = backtest_stats(account_value=df_account_value)\n",
    "    print(f\"=============={model_name} Results===========\")\n",
    "    print(stats)\n",
    "\n",
    "    # select the performance metric for tuning\n",
    "    cumulative_returns = stats['Cumulative returns']\n",
    "    sharpe_ratio = stats['Sharpe ratio']\n",
    "    performance_metric = cumulative_returns + sharpe_ratio\n",
    "    return -performance_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(param_spaces[\"a2c\"])\n",
    "def evaluate_a2c(**params):\n",
    "    model_kwargs = {\n",
    "        \"n_steps\": params[\"n_steps\"],\n",
    "        \"ent_coef\": params[\"ent_coef\"],\n",
    "        \"learning_rate\": params[\"learning_rate\"],\n",
    "        \"batch_size\": params[\"batch_size\"],\n",
    "    }\n",
    "    trained_model = model_train(\"a2c\", stock_env, model_kwargs)\n",
    "    env = StockTradingEnv(df = test, turbulence_threshold = 70, **env_kwargs)\n",
    "    return model_eval(\"ppo\", env, trained_model)\n",
    "\n",
    "@use_named_args(param_spaces[\"ddpg\"])\n",
    "def evaluate_ddpg(**params):\n",
    "    model_kwargs = {\n",
    "        \"buffer_size\": params[\"buffer_size\"],\n",
    "        \"learning_rate\": params[\"learning_rate\"],\n",
    "        \"batch_size\": params[\"batch_size\"],\n",
    "        \"tau\": params[\"tau\"],\n",
    "    }\n",
    "    trained_model = model_train(\"ddpg\", stock_env, model_kwargs)\n",
    "    env = StockTradingEnv(df = test, turbulence_threshold = 70, **env_kwargs)\n",
    "    return model_eval(\"ppo\", env, trained_model)\n",
    "\n",
    "@use_named_args(param_spaces[\"td3\"])\n",
    "def evaluate_td3(**params):\n",
    "    model_kwargs = {\n",
    "        \"buffer_size\": params[\"buffer_size\"],\n",
    "        \"learning_rate\": params[\"learning_rate\"],\n",
    "        \"batch_size\": params[\"batch_size\"],\n",
    "        \"tau\": params[\"tau\"],\n",
    "        \"policy_noise\": params[\"policy_noise\"],\n",
    "        \"noise_clip\": params[\"noise_clip\"],\n",
    "        \"policy_freq\": params[\"policy_freq\"],\n",
    "    }\n",
    "    trained_model = model_train(\"td3\", stock_env, model_kwargs)\n",
    "    env = StockTradingEnv(df = test, turbulence_threshold = 70, **env_kwargs)\n",
    "    return model_eval(\"ppo\", env, trained_model)\n",
    "\n",
    "@use_named_args(param_spaces[\"sac\"])\n",
    "def evaluate_sac(**params):\n",
    "    model_kwargs = {\n",
    "        \"buffer_size\": params[\"buffer_size\"],\n",
    "        \"learning_rate\": params[\"learning_rate\"],\n",
    "        \"batch_size\": params[\"batch_size\"],\n",
    "        \"tau\": params[\"tau\"],\n",
    "        \"ent_coef\": params[\"ent_coef\"],\n",
    "    }\n",
    "    trained_model = model_train(\"sac\", stock_env, model_kwargs)\n",
    "    env = StockTradingEnv(df = test, turbulence_threshold = 70, **env_kwargs)\n",
    "    return model_eval(\"ppo\", env, trained_model)\n",
    "\n",
    "@use_named_args(param_spaces[\"ppo\"])\n",
    "def evaluate_ppo(**params):\n",
    "    model_kwargs = {\n",
    "        \"n_steps\": params[\"n_steps\"],\n",
    "        \"ent_coef\": params[\"ent_coef\"],\n",
    "        \"learning_rate\": params[\"learning_rate\"],\n",
    "        \"batch_size\": params[\"batch_size\"],\n",
    "    }\n",
    "    trained_model = model_train(\"ppo\", stock_env, model_kwargs)\n",
    "    env = StockTradingEnv(df = test, turbulence_threshold = 70, **env_kwargs)\n",
    "    return model_eval(\"ppo\", env, trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2c_res = gp_minimize(evaluate_ppo, param_spaces[\"a2c\"], n_calls=50)\n",
    "print(\"Minimum parameter:\", a2c_res.x)\n",
    "print(\"Minimum objective: \", a2c_res.fun)\n",
    "\n",
    "ddpg_res = gp_minimize(evaluate_ddpg, param_spaces[\"ddpg\"], n_calls=50)\n",
    "print(\"Minimum parameter:\", ddpg_res.x)\n",
    "print(\"Minimum objective: \", ddpg_res.fun)\n",
    "\n",
    "td3_res = gp_minimize(evaluate_td3, param_spaces[\"td3\"], n_calls=50)\n",
    "print(\"Minimum parameter:\", td3_res.x)\n",
    "print(\"Minimum objective: \", td3_res.fun)\n",
    "\n",
    "sac_res = gp_minimize(evaluate_sac, param_spaces[\"sac\"], n_calls=50)\n",
    "print(\"Minimum parameter:\", sac_res.x)\n",
    "print(\"Minimum objective: \", sac_res.fun)\n",
    "\n",
    "ppo_res = gp_minimize(evaluate_ppo, param_spaces[\"ppo\"], n_calls=50)\n",
    "print(\"Minimum parameter:\", ppo_res.x)\n",
    "print(\"Minimum objective: \", ppo_res.fun)\n",
    "\n",
    "with open(\"res.txt\", \"w\") as output:\n",
    "    output.write(str(a2c_res.x))\n",
    "    output.write(str(a2c_res.fun))\n",
    "    output.write(str(ddpg_res.x))\n",
    "    output.write(str(ddpg_res.fun))\n",
    "    output.write(str(td3_res.x))\n",
    "    output.write(str(td3_res.fun))\n",
    "    output.write(str(sac_res.x))\n",
    "    output.write(str(sac_res.fun))\n",
    "    output.write(str(ppo_res.x))\n",
    "    output.write(str(ppo_res.fun))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emsamble DRL Agent ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
    "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
    "\n",
    "ensemble_agent = DRLEnsembleAgent(df=train,\n",
    "                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n",
    "                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n",
    "                 rebalance_window=rebalance_window, \n",
    "                 validation_window=validation_window, \n",
    "                 **env_kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2C_model_kwargs = {\n",
    "                    'n_steps': 5,\n",
    "                    'ent_coef': 0.005,\n",
    "                    'learning_rate': 0.0007\n",
    "                    }\n",
    "\n",
    "PPO_model_kwargs = {\n",
    "                    \"ent_coef\":0.01,\n",
    "                    \"n_steps\": 2048,\n",
    "                    \"learning_rate\": 0.00025,\n",
    "                    \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "DDPG_model_kwargs = {\n",
    "                      #\"action_noise\":\"ornstein_uhlenbeck\",\n",
    "                      \"buffer_size\": 10_000,\n",
    "                      \"learning_rate\": 0.0005,\n",
    "                      \"batch_size\": 64\n",
    "                    }\n",
    "\n",
    "timesteps_dict = {'a2c' : 10_000, \n",
    "                 'ppo' : 10_000, \n",
    "                 'ddpg' : 10_000\n",
    "                 }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training with ensemble DRL agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
    "                                                 PPO_model_kwargs,\n",
    "                                                 DDPG_model_kwargs,\n",
    "                                                 timesteps_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stocks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
