{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/.local/lib/python3.10/site-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import yfinance as yf\n",
    "\n",
    "from finrl.meta.data_processor import DataProcessor \n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent \n",
    "from stable_baselines3.common.logger import configure\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from argparse import ArgumentParser \n",
    "\n",
    "import itertools\n",
    "import pyfolio\n",
    "from pyfolio import timeseries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    ")\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_START_DATE = '2015-01-01'\n",
    "TRAIN_END_DATE = '2020-01-01'\n",
    "TEST_START_DATE = '2020-01-02'\n",
    "TEST_END_DATE = '2022-12-01'\n",
    "TRADE_START_DATE = '2022-12-01'\n",
    "TRADE_END_DATE = '2023-04-01'\n",
    "TIME_INTERVAL = '1D'\n",
    "\n",
    "ticker_list = ['600000.SH', '600009.SH', '600016.SH', '600028.SH', '600030.SH', '600031.SH', \n",
    "               '600036.SH', '600050.SH', '600104.SH', '600196.SH', '600276.SH', '600309.SH', \n",
    "               '600519.SH', '600547.SH', '600570.SH']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (61221, 8)\n"
     ]
    }
   ],
   "source": [
    "df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
    "                     end_date = TRADE_END_DATE,\n",
    "                     ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Indicator to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (2075, 8)\n",
      "Successfully added vix\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = INDICATORS,\n",
    "                    use_vix=True,\n",
    "                    use_turbulence=True,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformat Data and write to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the only tic and date\n",
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "# get the processed full data\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "# fill the missing values with zero\n",
    "processed_full = processed_full.fillna(0)\n",
    "\n",
    "# sort the data and reset index\n",
    "processed_full.sort_values(['date','tic'],ignore_index=True)\n",
    "\n",
    "# write to csv file\n",
    "processed_full.to_csv(\"dow_30.csv\",index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Data from csv file (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_full = pd.read_csv(\"dow_30.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>27.847500</td>\n",
       "      <td>27.860001</td>\n",
       "      <td>26.837500</td>\n",
       "      <td>24.531765</td>\n",
       "      <td>212818400.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.163582</td>\n",
       "      <td>23.208843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>24.531765</td>\n",
       "      <td>24.531765</td>\n",
       "      <td>17.790001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>160.160004</td>\n",
       "      <td>162.589996</td>\n",
       "      <td>158.600006</td>\n",
       "      <td>127.031990</td>\n",
       "      <td>2605400.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.163582</td>\n",
       "      <td>23.208843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>127.031990</td>\n",
       "      <td>127.031990</td>\n",
       "      <td>17.790001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>AXP</td>\n",
       "      <td>93.169998</td>\n",
       "      <td>93.940002</td>\n",
       "      <td>92.139999</td>\n",
       "      <td>81.897881</td>\n",
       "      <td>2437500.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.163582</td>\n",
       "      <td>23.208843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>81.897881</td>\n",
       "      <td>81.897881</td>\n",
       "      <td>17.790001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>BA</td>\n",
       "      <td>131.070007</td>\n",
       "      <td>131.839996</td>\n",
       "      <td>129.089996</td>\n",
       "      <td>113.657204</td>\n",
       "      <td>4294200.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.163582</td>\n",
       "      <td>23.208843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>113.657204</td>\n",
       "      <td>113.657204</td>\n",
       "      <td>17.790001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>CAT</td>\n",
       "      <td>91.769997</td>\n",
       "      <td>92.370003</td>\n",
       "      <td>90.660004</td>\n",
       "      <td>72.221130</td>\n",
       "      <td>3767900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.163582</td>\n",
       "      <td>23.208843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>72.221130</td>\n",
       "      <td>72.221130</td>\n",
       "      <td>17.790001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   tic        open        high         low       close   \n",
       "0  2015-01-02  AAPL   27.847500   27.860001   26.837500   24.531765  \\\n",
       "1  2015-01-02  AMGN  160.160004  162.589996  158.600006  127.031990   \n",
       "2  2015-01-02   AXP   93.169998   93.940002   92.139999   81.897881   \n",
       "3  2015-01-02    BA  131.070007  131.839996  129.089996  113.657204   \n",
       "4  2015-01-02   CAT   91.769997   92.370003   90.660004   72.221130   \n",
       "\n",
       "        volume  day  macd    boll_ub    boll_lb  rsi_30     cci_30  dx_30   \n",
       "0  212818400.0  4.0   0.0  25.163582  23.208843     0.0 -66.666667  100.0  \\\n",
       "1    2605400.0  4.0   0.0  25.163582  23.208843     0.0 -66.666667  100.0   \n",
       "2    2437500.0  4.0   0.0  25.163582  23.208843     0.0 -66.666667  100.0   \n",
       "3    4294200.0  4.0   0.0  25.163582  23.208843     0.0 -66.666667  100.0   \n",
       "4    3767900.0  4.0   0.0  25.163582  23.208843     0.0 -66.666667  100.0   \n",
       "\n",
       "   close_30_sma  close_60_sma        vix  turbulence  \n",
       "0     24.531765     24.531765  17.790001         0.0  \n",
       "1    127.031990    127.031990  17.790001         0.0  \n",
       "2     81.897881     81.897881  17.790001         0.0  \n",
       "3    113.657204    113.657204  17.790001         0.0  \n",
       "4     72.221130     72.221130  17.790001         0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splite the data into training set and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE)\n",
    "test = data_split(processed_full, TEST_START_DATE,TEST_END_DATE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the stock dimension and state space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 29, State Space: 291\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "env_train = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train DRL Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to results/ppo\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "\n",
    "# set up logger\n",
    "tmp_path = RESULTS_DIR + \"/ppo\"\n",
    "new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "# Set new logger\n",
    "model_ppo.set_logger(new_logger_ppo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.26e+03  |\n",
      "|    ep_rew_mean     | 57.2      |\n",
      "| time/              |           |\n",
      "|    fps             | 266       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 7         |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 0.3605704 |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.26e+03     |\n",
      "|    ep_rew_mean          | 55.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.017304406  |\n",
      "|    clip_fraction        | 0.195        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.2        |\n",
      "|    explained_variance   | -0.0367      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.61         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0406      |\n",
      "|    reward               | -0.012038707 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 5.73         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 57.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019258745 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.0364     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.7         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    reward               | 1.5282221   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 5.86        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 55.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019978933 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | 0.0442      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.52        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.034      |\n",
      "|    reward               | 0.69062513  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 5.66        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 56.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018149922 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.0263     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.47        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    reward               | 1.245791    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 4.81        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 58.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022996008 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | -0.00769    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.49        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    reward               | 1.6241438   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 6.11        |\n",
      "-----------------------------------------\n",
      "day: 1257, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1707278.30\n",
      "total_reward: 707278.30\n",
      "total_cost: 179097.32\n",
      "total_trades: 33999\n",
      "Sharpe: 0.861\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 59          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026148694 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | 0.0311      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.42        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    reward               | -0.21214089 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 4.88        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.26e+03   |\n",
      "|    ep_rew_mean          | 56.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 229        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 71         |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01979364 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.6      |\n",
      "|    explained_variance   | 0.015      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.12       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.031     |\n",
      "|    reward               | 0.1021708  |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 6.3        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.26e+03   |\n",
      "|    ep_rew_mean          | 57.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 228        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 80         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02491382 |\n",
      "|    clip_fraction        | 0.266      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.6      |\n",
      "|    explained_variance   | 0.0429     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.77       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0312    |\n",
      "|    reward               | -3.1746113 |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 5.7        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 59.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 226         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02057062  |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | 0.0909      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.11        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    reward               | -0.07863538 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 5.47        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 58.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023403296 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | 0.07        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.06        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    reward               | 0.1344926   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 7.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 59          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025841366 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.59        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    reward               | 0.22983474  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 5.23        |\n",
      "-----------------------------------------\n",
      "day: 1257, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1403340.80\n",
      "total_reward: 403340.80\n",
      "total_cost: 175275.85\n",
      "total_trades: 33231\n",
      "Sharpe: 0.539\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 57.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 222         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027775653 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.3         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    reward               | 0.4763807   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 4.48        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 58          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027497368 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.7         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    reward               | -2.874003   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 5.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 58.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028065402 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.59        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    reward               | 0.072103195 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 4.74        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 58.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024468796 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.46        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    reward               | -1.2515635  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 4.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 59.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030047694 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.92        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    reward               | -0.11290255 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 5.29        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 60.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 220         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0266563   |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | 0.137       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.12        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    reward               | 0.111224696 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 6.17        |\n",
      "-----------------------------------------\n",
      "day: 1257, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1751697.87\n",
      "total_reward: 751697.87\n",
      "total_cost: 172596.68\n",
      "total_trades: 32905\n",
      "Sharpe: 0.839\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 60.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 220         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030343827 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | 0.074       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.26        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    reward               | 2.0333564   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 6.99        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 60.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027850702 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.23        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    reward               | 1.1273667   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 5.75        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 61.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032615893 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.3       |\n",
      "|    explained_variance   | 0.0251      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    reward               | -0.9908228  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 4.82        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 62          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 203         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023867948 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.3       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.76        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    reward               | -0.68677926 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 6.96        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 64.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 213         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026864262 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.3       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.63        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    reward               | -0.2742733  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 5.81        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 65.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 222         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023426406 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.95        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    reward               | 0.41505018  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 5.04        |\n",
      "-----------------------------------------\n",
      "day: 1257, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1702446.31\n",
      "total_reward: 702446.31\n",
      "total_cost: 150470.05\n",
      "total_trades: 31774\n",
      "Sharpe: 0.809\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 65.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 220         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 231         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024911188 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.72        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    reward               | 0.1807815   |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 6.64        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=50000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stocks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
